---
title: "Homework1"
author: "Luis Noguera"
date: "4/6/2020"
output: html_document
---

## Initial Set Up
```{r warning=FALSE, echo=TRUE, eval= TRUE, message = F}

# Importing libraries and set up the work environment
library(knitr)
library(readxl)
library(tidyverse)
library(dplyr)
library(tidymodels)
library(janitor)
library(plotly)
library(rpart)
library(readr)
library(tidymodels)

knitr::opts_chunk$set(cache = TRUE, 
                      warning = FALSE, 
                      echo = TRUE,
                      message = FALSE,
                      dpi = 180, 
                      fig.width = 6, 
                      fig.height = 4)


theme_set(theme_classic())

```

# Problem 1


## 1.0 Data Import

```{r}

age <- read_excel("age_stats315B.xlsx") 


age <- age %>%
  mutate_if(is.character, as.numeric) %>% # Changing all values to numeric
  janitor::clean_names()

age

age <- age %>%
  mutate_at(vars(occup,
                  type_home,
                  lang,
                  ethnic,
                  edu,
                  sex,
                  mar_stat,
                 dual_inc,
                 house_stat
                 ),
             funs(factor))
                
```

## 1.1 Quick Exploration

```{r}

library(skimr)

skim(age)

# Cheking for missing values
summary(age)

```

**Note**
There are some missing values in Education, Income, Ethnic, Persons and Language. 


## 1.2 Data Split

```{r}

library(tidymodels)

set.seed(415)
age_split <- initial_split(age)

age_train <- training(age_split)

age_test <- testing(age_split)

```

## 1.3 Decision Tree - Age 

```{r}
# Loading Tree Model Libraries 
library(rpart)
library(rpart.plot)

colnames(age)
age_model <- rpart(age ~ .,
                   data = age_train)

rpart.plot(age_model)

```
**Write a short report about the relation between the age and the other demographic predictors as obtainedfrom the RPART output and answer the following questions:**

The optimal decision tree using all the variables, make 7 splits. Marital Status is the variable with the most predictive power since it's found at the top of the tree, followed by occupation and householder status. 

The first and most important split is at marital_status if a person is *Single - Never Married* or *Living Together, not Married* this person is likely to be one of a younger group. Aftewards, if the person *Lives with Parents/Family* and education is *11 grade or less* this person is very likely to be in the lowest group age of the dataset. On the contrary, the oldest group of people is likely to be people that are not  *Single or are note living together*, and answered occupation as being *retired*. 

**(a) Were surrogate splits used in the construction of the optimal tree you obtained? Whatdoes a surrogate split mean? Give an example of a surrogate split from your optimal decisiontree. Which variable is the split on? Which variable(s) is the surrogate split on?**

As it can be seen from the summaru of the model, surrogates splits have been used to handle the missing data in the age dataset. When the missing observation is missing from the primary split variable; the examined observation is bucketed based on the saved surrogate daughter node. 

For example, there are 13 mising values in node 4 data where data is splitted based on education. The surrogate variable in this case is number of Under18 in the house, this variable has an agreement of 0.721 with the primary one. Less than 0.5 Under18 would make the split to an older age group.  

```{r}

summary(age_model)

```

**(b) Using your optimal decision tree, predict your age.**

The model does an excellent job at predicting my age. It classifies my age to be 3 meaning I am between *25 thru 34*. I am turning 26 next week, so it predicted my age accurately.

```{r}

# Making my dataframe and choosing the right type for each column 
Luis_Noguera <- data.frame( age = 3, 
                   occup  = 1,
                   type_home  = 3,
                   sex  = 1,
                   mar_stat  = 5, 
                   edu  = 6,
                   income  = 9,
                   live_ba  = 2,
                   dual_inc  = 1,
                   persons  = 2,
                   under18  = 0,
                   house_stat  = 2,
                   ethnic  = 5,
                  lang = 2)  %>%
   mutate_at(vars(occup,
                  type_home,
                  lang,
                  ethnic,
                  edu,
                  sex,
                  mar_stat,
                 dual_inc,
                 house_stat
                 ),
             funs(factor)) %>%
  select(-age)

myage_pred <- predict(age_model, Luis_Noguera)

myage_pred

```

# Problem 2


## 2.0 Data Import 

```{r}
library(readr)
housetype <- read_csv("housetype_stats315B.csv")

housetype <- housetype %>%
  mutate_at(vars(Ethnic, 
                 HouseStat,
                 Lang,
                 MarStat,
                 Occup,
                 TypeHome,
                 sex), funs(factor))


```


## 2.1 Data Split

```{r}

set.seed(415)

housetype_df <- initial_split(housetype)


housetype_train <- training(housetype_df)
housetype_test <- testing(housetype_df)


```

## 2.3 Data Exploration


```{r}


housetype %>%
  count(TypeHome) %>%
  ggplot(aes(x = TypeHome, y = `n`, fill = TypeHome)) +
  geom_col() +
  labs(y = 'Number of Homes') -> homes_hist

homes_hist


housetype %>%
  group_by(TypeHome) %>%
  summarise(mean_age = mean(age),
            mean_income = mean(Income)) %>%
  ggplot(aes(x = TypeHome, y = mean_age)) +
  geom_col() -> mean_age_visz

mean_age_visz


```


## 2.4 Decision Tree Model - House Type


After fitting the model and plotting the decision tree, I found that the model classified only two classes. Type of homes 3 (apartment) and 1 (house). The heavily unbalanced class in the target variable forced the split to the highest repeated clases. If the analyst or statistician is find with this results, prediction only two classes he or she can stay with this model. On the contrary, we can decide to stratify the data to get a more balance distribution of classes, upsample or downbalance the data to fit a new model with an even number of classes. 

The most important variable to make the first split is HouseStat 1 or 3, the second one is the number of people living in the property, higher or lower than 3, lastly is the Income level, those earning in the categories lower than 4 are more likely to live in an apartment, those with an income level of 4 or higher are more likely to live in house. 


```{r}
set.seed(232)
house_model <- rpart(TypeHome ~ ., 
                     data = housetype_train) # Fititng the model

rpart.plot(house_model) # PLotting the decision tree model


# From tidymodels package to get the probabilities 
tree_res <- predict(house_model,
                    new_data = housetype_test)

predicitions <- apply(tree_res, 1, 
                      function(x) 
                        return(which(x == max(x))))

error_rate <- sum(predicitions != housetype_test[,1]) / length(predicitions)


```


# Problem 3


**If the model predicts well on the training data but not on the testing one could be for mainly two reasons:**

1. The new data to predict, in this case the test set and the training data set variable's differ considerably in their distribution and variance. Estimating house prices in 2020, using data predictors from a dataset collected in 1930 would not yield a strong and optimistic predictive model. 

2. The model fitted to closely the observations in the training data set, so that when new data is presented it does not genealize well on the new observations.

# Problem 4

**Why canâ€™t the prediction function be chosen from the class of all possible functions.**


In theory the optimal fucntion would have 0 bias. However, with so many possible functions to be selected for a problem this would be computationally impossible to do. This is when the art of an analyst//statistician comes into play to select and discover those variables that better estimate the outcome. Also, if electing all possible functions was an alternative the amount of variance to be explained by the variables in the function would be huge, therefore not doing a great job at estimating with accuracy in the response variable. 

# Problem 5

**What is the definition of the target function for a given problem. Is it always an accurate function for prediction. Why/why not.**

The target function refers to the function of all possible alterantives that minimizes the expected prediciton risk. If there is no association between predictors and response than the model would de deficient. If we were tryine to predict the weather based on the number of people in a city, the best predictive model for would perform poorly. 

# Problem 6

**Is the empirical risk evaluated on the training data always the best surrogate for the actual (population) prediction risk. Why/why not. In what settings would it be expected to be good.**


This is not true. Two reasons: if the population distribution of the training data does not accurately represent the distribution of the actual data, then the model would strongly underestimate the predictio risk. For example, a model that is trying to predict the next presidential winner in US and only considers the population of one small city or small state without considering the other states or countries. The model would be accurate for the small city but not a good representation on the rest of the country's opinion. Second, one is related to overfitting. The training data set is still and underestimate of the population even when the split occurred from the same dataset. Models that are fit too close, capture the fluctuations in the training set that may be inaccuratelly represented in the testing data set. 

# Problem 7

**Suppose the loss for an incorrect classification prediction is the same regardless of either the predicted value ck or the true value cl of the outcome y.  Show that in this case misclassification risk reduces to the classification error rate. What is the Bayes rule for this case in terms of the probabilities of y realizing each of its values {Pr(y=ck)}Kk=1? Derive this rule from the general (unequal loss) Bayes rule, for this particular loss structure Lkl= 1(k=l).**

## To be completed!

Misclassification risk is defined as $E_{yx}L(y, c(x))$, the expectation over y and x of the loss incurred from predicting $c(x)$ when the answer was y. In our case, that loss is simply an indicator function that is 0 when the classifications are the same and 0 otherwise. $E_{yx}I(y \neq c(x)) = mean(I(y \neq c(x)))$ which is equivalent to the classification error rate!

The general Bayes decision rule for unequal costs is:
$$\hat{k} = min_{k \in {1...K}} R(c_k | x)$$ where
$R(c_k | x) = \sum_{l = 1}^{K}L_{kl} P(y = c_l | x)$, and 
$L_{kl}$ is the loss incurred from predicting class $k$ when the true class is $l$.
In our case, $L_{kl} = I(k \neq l)$.

In our case, since $L_{kl} = I(k \neq l)$, the risk of predicting $c_k$ is 
$$\sum_{l \neq k} P(y = c_l | x).$$
In essence, this is just the probability that we are incorrect when we predict $c_k$.  This quantity is minimized when we choose the most probable label for $Y$ given $x$. Thus, our Bayes rule is:
$$\hat{k} = max_{k \in {1...K}} P(y = c_k | x).$$



# Problem 8


**Does a low error rate using a classification rule derived by substituting probability estimates {Pr(y=ck)}Kk=1 in place of the true probabilities{Pr(y=ck)}Kk=1 in the Bayes rule imply accurate estimates of those probabilities? Why?**


This is not accurate because during the classification, one could know that ther is an unbalance data set or response variable. The classification task could do a very poor job of predicting the probabilities for each class. However, one can skew the loss in a way that the probability of the correct class is lower, even when the risk of the correct class was already slim due to the penalty for misscalsification of the underrepresented class. 



# Problem 9

 **Explain the bias-variance trade-off**
 
 
In order to build a good model that predicts well on training and future data, there needs to be good balance of bias and variance that minimizes the total error. If the model is to simple with few predictors and does not capture mich of the variance it is likely to result in high bias and low variance, on the contrary if the model has a large number of parameters it is prompt to have high variance and low bias. A good model is one with the right balance, without underfitting or overfitting the data in hand. When giving up the complexity towards bias or variance we gain on the other one; however it is impossible to make a model more complex and less complex at the same time. 



# Problem 10

**Why not choose surrogate splits to best predict the outcome variableyrather thanthe primary split.**
 
When using surrogate splits, there is a lose of infromation on the primary variable in which the algorithm is making the split. There is only as much correlation between the surrogate and the primary varible to capture information and do a proper classification split. 



# Problem 11

## To be completed!

# Problem 12 
 
## To be completed! Math heavy!
 
# Problem 13
 
**Derive an updating formula for calculating the change in the improvement in prediction risk as the result of a split when the split is modified by one observation changing sides.**


![Solution problem 13](/Users/luisnoguera/Documents/Data Mining Homeworks/Applied_Modern_Statistics/IMG_0868.jpg)

 

# Problem 14


Even when it allow us to achieve a small training error, is not the always best approach to increase the size of the function class. 
Some reasons that an increase in the funciton class may hurt the result are as follows:

1. Even thought when an increase in the size of the function class usually decreases the bias in the model, often it increases the variance. This means that with an optimal function with larger function class may be closer or precise to the target on the training dataset, the optimal function after redicting on training data may vary widly, based on different patterns found in the training data. This can cause the Mean Squared Error to increase when evaluating unseen data. 

2. It is harder to optimize over greater number of class funtions. 

In a simmilar fashion, decreasing the size of the function class may lead to high bias, because we would be making the model more simple and reducing the variance of the independent variables to estimate the target variable. 

# Problem 15

**The recursive partitioning strategy described in class for building decision trees uses two-way (binary) splits at each step. This is not fundamental, and one could envision multi-way splits of each non-terminal node creating several (rather than two) daughter regions with each split. What would be the relative advantages and disadvantages of a such a multi-way splitting strategy?**

First, a multi-way split on each node would improve the accuracy on the training data. Secondly, this approach would allow to easily and more effectively split the target variable earlier in the model with the higher correlated predictors to the outcome variable. 

On the down side, not specifying the number of splits per node may increase the redundancy in the split as a two-way split could be enough split in at the variable. Another disadvantage is that a higher number of splits in the node could increase the chances of overfitting the training data and a poor model whe new data is presented. 


# Problem 16


The nature of the decision tree in this case is that allows the linear combination splits to increase the accuracy of the statistical model. Enabling piecewise linear splitting may increase the accuracy in those areas with more variance of output variables, specially since one of the disadvantages of regressiong trees is that it is restricted to piecewise continous fucntions.  

 
On the other hand, this strategy if not generalized in any way can lead to overfitting. It would also increase the computational effort used to calculate optimal separating hyperplanes. Finally, this approach would decrease the ability to make suitable interpretations. In this case we would have statements on combinations that fall into one half space or another, this is of course less interpretable than in a two-way split. 


